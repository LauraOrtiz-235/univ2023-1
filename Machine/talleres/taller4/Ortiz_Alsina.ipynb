{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "447f62aa84d44c3b89ba17001d269b76",
    "deepnote_cell_type": "markdown",
    "id": "vNsa-hmja1h-"
   },
   "source": [
    "# Ejercicio de introducción a Pytorch\n",
    "Haremos un recorrido por los aspectos fundamentales de pytroch desde el manejo de tensores hasta el entrenamiento y evaluación de una red neuronal. \n",
    "Para completarlo podemos consultar\n",
    " [ESTE](https://colab.research.google.com/github/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/Introduction_to_PyTorch.ipynb#scrollTo=u-L7YQmcHvX8) cuaderno.y otros recursos dados a lo largo del cuaderno.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8278c447d83049c8902f9aa642a88287",
    "deepnote_cell_type": "markdown",
    "id": "POmirEwBbj1P"
   },
   "source": [
    "Primero importamos algunas librerías básicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "4450fb38923c4226803e9491676494be",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3338,
    "execution_start": 1679001680648,
    "source_hash": "681e86b0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /home/laura/anaconda3/lib/python3.9/site-packages (7.6.5)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /home/laura/anaconda3/lib/python3.9/site-packages (from ipywidgets) (7.29.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /home/laura/anaconda3/lib/python3.9/site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/laura/anaconda3/lib/python3.9/site-packages (from ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /home/laura/anaconda3/lib/python3.9/site-packages (from ipywidgets) (1.0.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /home/laura/anaconda3/lib/python3.9/site-packages (from ipywidgets) (3.5.1)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /home/laura/anaconda3/lib/python3.9/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/laura/anaconda3/lib/python3.9/site-packages (from ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /home/laura/anaconda3/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /home/laura/anaconda3/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /home/laura/anaconda3/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.4.1)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /home/laura/anaconda3/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/laura/anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: decorator in /home/laura/anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/laura/anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (58.0.4)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/laura/anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: backcall in /home/laura/anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pygments in /home/laura/anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/laura/anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /home/laura/anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/laura/anaconda3/lib/python3.9/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: pyzmq>=13 in /home/laura/anaconda3/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/laura/anaconda3/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /home/laura/anaconda3/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.8.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /home/laura/anaconda3/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/laura/anaconda3/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/laura/anaconda3/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/laura/anaconda3/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/laura/anaconda3/lib/python3.9/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/laura/anaconda3/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /home/laura/anaconda3/lib/python3.9/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.5)\n",
      "Requirement already satisfied: argon2-cffi in /home/laura/anaconda3/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.1.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/laura/anaconda3/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.9.4)\n",
      "Requirement already satisfied: prometheus-client in /home/laura/anaconda3/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.11.0)\n",
      "Requirement already satisfied: nbconvert in /home/laura/anaconda3/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.1.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /home/laura/anaconda3/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: jinja2 in /home/laura/anaconda3/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.3)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /home/laura/anaconda3/lib/python3.9/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /home/laura/anaconda3/lib/python3.9/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/laura/anaconda3/lib/python3.9/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: testpath in /home/laura/anaconda3/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /home/laura/anaconda3/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/laura/anaconda3/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/laura/anaconda3/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /home/laura/anaconda3/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in /home/laura/anaconda3/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /home/laura/anaconda3/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.3)\n",
      "Requirement already satisfied: bleach in /home/laura/anaconda3/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.0.0)\n",
      "Requirement already satisfied: async-generator in /home/laura/anaconda3/lib/python3.9/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in /home/laura/anaconda3/lib/python3.9/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: packaging in /home/laura/anaconda3/lib/python3.9/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.0)\n",
      "Requirement already satisfied: webencodings in /home/laura/anaconda3/lib/python3.9/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/laura/anaconda3/lib/python3.9/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.1-cp39-cp39-manylinux1_x86_64.whl (6.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.0 MB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/laura/anaconda3/lib/python3.9/site-packages (from torchvision) (1.20.3)\n",
      "Requirement already satisfied: requests in /home/laura/anaconda3/lib/python3.9/site-packages (from torchvision) (2.26.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/laura/anaconda3/lib/python3.9/site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: torch==2.0.0 in /home/laura/anaconda3/lib/python3.9/site-packages (from torchvision) (2.0.0)\n",
      "Requirement already satisfied: networkx in /home/laura/anaconda3/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (2.6.3)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/laura/anaconda3/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (11.7.101)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/laura/anaconda3/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/laura/anaconda3/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/laura/anaconda3/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (10.2.10.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/laura/anaconda3/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions in /home/laura/anaconda3/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (3.10.0.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/laura/anaconda3/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/laura/anaconda3/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/laura/anaconda3/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/laura/anaconda3/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (8.5.0.96)\n",
      "Requirement already satisfied: filelock in /home/laura/anaconda3/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (3.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/laura/anaconda3/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (11.7.99)\n",
      "Requirement already satisfied: sympy in /home/laura/anaconda3/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (1.9)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/laura/anaconda3/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/laura/anaconda3/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (11.7.91)\n",
      "Requirement already satisfied: jinja2 in /home/laura/anaconda3/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (2.11.3)\n",
      "Requirement already satisfied: setuptools in /home/laura/anaconda3/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchvision) (58.0.4)\n",
      "Requirement already satisfied: wheel in /home/laura/anaconda3/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchvision) (0.37.0)\n",
      "Requirement already satisfied: cmake in /home/laura/anaconda3/lib/python3.9/site-packages (from triton==2.0.0->torch==2.0.0->torchvision) (3.26.0)\n",
      "Requirement already satisfied: lit in /home/laura/anaconda3/lib/python3.9/site-packages (from triton==2.0.0->torch==2.0.0->torchvision) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/laura/anaconda3/lib/python3.9/site-packages (from jinja2->torch==2.0.0->torchvision) (1.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/laura/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/laura/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/laura/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/laura/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (1.26.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/laura/anaconda3/lib/python3.9/site-packages (from sympy->torch==2.0.0->torchvision) (1.2.1)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.15.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "2aad5a4276eb4084a1e7d5238f4ce0c6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1679001684394,
    "id": "YlhqXdgsF7fC",
    "source_hash": "b70b8c55"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10158/3787987072.py:11: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import math\n",
    "import numpy as np \n",
    "import time\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgba\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "## Progress bar\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "0d7e1ef55677465fbe33de7ab81df2c4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7,
    "execution_start": 1679001693492,
    "id": "UtUr7QYZHon3",
    "source_hash": "5e49d3"
   },
   "outputs": [],
   "source": [
    "#Pytorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "152e21c1509d4b469833c96844c1bfcb",
    "deepnote_cell_type": "markdown",
    "id": "IdbqZ1kazh4b"
   },
   "source": [
    "Primero recordemos algunas funconalidades de los tensores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "115a3880213e44209e00ea7215c3cfb8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7,
    "execution_start": 1679001695192,
    "id": "g9W98Co-sapv",
    "outputId": "e2198074-36fb-4645-90d8-becfb1b89f8c",
    "source_hash": "e50d70ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1254, 0.6853, 0.3088],\n",
       "         [0.5734, 0.0960, 0.9100],\n",
       "         [0.7195, 0.6008, 0.7725],\n",
       "         ...,\n",
       "         [0.8170, 0.6585, 0.4985],\n",
       "         [0.5790, 0.9788, 0.3703],\n",
       "         [0.4884, 0.7518, 0.8582]],\n",
       "\n",
       "        [[0.1856, 0.8100, 0.5897],\n",
       "         [0.6845, 0.4525, 0.0825],\n",
       "         [0.0888, 0.8651, 0.8567],\n",
       "         ...,\n",
       "         [0.7247, 0.3878, 0.3012],\n",
       "         [0.2268, 0.1319, 0.8044],\n",
       "         [0.5168, 0.4058, 0.7381]],\n",
       "\n",
       "        [[0.6279, 0.8568, 0.3580],\n",
       "         [0.9818, 0.7178, 0.9283],\n",
       "         [0.1157, 0.1949, 0.8583],\n",
       "         ...,\n",
       "         [0.0143, 0.2146, 0.3869],\n",
       "         [0.5130, 0.9616, 0.3036],\n",
       "         [0.9442, 0.1870, 0.7162]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.1275, 0.0562, 0.8738],\n",
       "         [0.3937, 0.8976, 0.7395],\n",
       "         [0.0328, 0.4909, 0.7699],\n",
       "         ...,\n",
       "         [0.1739, 0.7769, 0.0014],\n",
       "         [0.2150, 0.8304, 0.5970],\n",
       "         [0.0167, 0.0261, 0.2475]],\n",
       "\n",
       "        [[0.4176, 0.1125, 0.0428],\n",
       "         [0.6898, 0.0515, 0.5956],\n",
       "         [0.5522, 0.9477, 0.2499],\n",
       "         ...,\n",
       "         [0.6779, 0.6640, 0.9290],\n",
       "         [0.8750, 0.4419, 0.5205],\n",
       "         [0.3603, 0.5529, 0.8993]],\n",
       "\n",
       "        [[0.5502, 0.4970, 0.3572],\n",
       "         [0.5010, 0.3930, 0.2723],\n",
       "         [0.8033, 0.2368, 0.1848],\n",
       "         ...,\n",
       "         [0.0246, 0.4903, 0.3320],\n",
       "         [0.9742, 0.0859, 0.5605],\n",
       "         [0.8754, 0.1752, 0.4369]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(100,110, 3)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": "49851e1118414f01ae09b54d2c05f091",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1679001696376,
    "id": "8LGQ0J7fsh0G",
    "outputId": "8d68890e-5140-4349-ee86-21373bd7fdae",
    "source_hash": "cbd53da6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 110])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.permute(t, (0,2,1)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "0aff0e0f0b8d4d19b2ae2a56c6dde973",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 41,
    "execution_start": 1679001698334,
    "id": "RYtN-PDlzhSP",
    "outputId": "6eb305f4-876e-42ba-a931-e37570846b7a",
    "source_hash": "e3b87c38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primer tensor: \n",
      "tensor([[0.5038, 0.6048, 0.0418],\n",
      "        [0.9056, 0.8686, 0.2401],\n",
      "        [0.4585, 0.9380, 0.4622]])\n",
      "Tamaño del primer tensor:  3\n",
      "Segundo tensor: \n",
      "tensor([[ 1.2634,  1.8075,  0.3350],\n",
      "        [-1.3284, -1.2582, -1.5467],\n",
      "        [ 0.8860, -0.8432,  0.5846]])\n",
      "Tamaño del segundo tensor:  3\n"
     ]
    }
   ],
   "source": [
    "# Crear un tensor aleatorio con entradas entre 0 y 1, de tamaño 3x3\n",
    "primer_tensor = torch.rand(3, 3)\n",
    "\n",
    "# Crear un tensor de tamaño 3x3 con valores en una distribución normal estandar\n",
    "segundo_tensor = torch.randn(3, 3)\n",
    "\n",
    "# Calcular el tamaño de los tensores\n",
    "primer_tensor_size = primer_tensor.size(dim=1)\n",
    "segundo_tensor_size = segundo_tensor.size(dim=1)\n",
    "\n",
    "# Imprimir los valores de los vectores y su tamaño\n",
    "print(\"Primer tensor: \")\n",
    "print(primer_tensor)\n",
    "print(\"Tamaño del primer tensor: \", primer_tensor_size)\n",
    "\n",
    "print(\"Segundo tensor: \") \n",
    "print(segundo_tensor)\n",
    "print(\"Tamaño del segundo tensor: \", segundo_tensor_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": "e59bfcd7a0f648caa598888cc4e5aed6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 91,
    "execution_start": 1679001700376,
    "id": "-FGFp5HhNhkY",
    "source_hash": "7b871fd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Crear una matriz de unos de tamaño 3 by 3\n",
    "tensor_of_ones = torch.ones(3, 3)\n",
    "\n",
    "# Crear una matrix identidad de tamaño 3 by 3\n",
    "identity_tensor = torch.eye(3)\n",
    "\n",
    "# Multiplicar las dos matrices anteriores\n",
    "matrices_multiplied = torch.matmul(tensor_of_ones, identity_tensor)\n",
    "print(matrices_multiplied)\n",
    "\n",
    "# ¿Qué ocurre si las multiplica usando * ?\n",
    "matrices_multiplied_error = tensor_of_ones * identity_tensor\n",
    "print(matrices_multiplied_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d9e0a6d3ec9245a49e796988046ed3a7",
    "deepnote_cell_type": "markdown",
    "id": "RNwlCf3PTdFX"
   },
   "source": [
    "### Cálculo de gradientes\n",
    "Calculemos un gradiente utilizando Pytorch. La función está en la gráfica Graph0.\n",
    "\n",
    "Para esto, puede ir a la sección Dynamic Computation Graph and Backpropagation, del cuaderno inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": "d8145aefea1c487389bb2591aec3e06b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 28,
    "execution_start": 1679001703922,
    "id": "exfqwUo0Oyb-",
    "outputId": "63d2103c-ac97-4f33-b2df-17e26ce4eef7",
    "source_hash": "8c2c64e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of x is: tensor(5.)\n",
      "Gradient of y is: tensor(5.)\n",
      "Gradient of z is: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Initialize x, y and z to values 4, -3 and 5\n",
    "x = torch.tensor(4., requires_grad = True)\n",
    "y = torch.tensor(-3., requires_grad = True)\n",
    "z = torch.tensor(5., requires_grad = True)\n",
    "\n",
    "# Set q to sum of x and y, set f to product of q with z\n",
    "q = x + y\n",
    "f = q * z\n",
    "\n",
    "# Compute the derivatives\n",
    "f.backward()\n",
    "\n",
    "# Print the gradients\n",
    "print(\"Gradient of x is: \" + str(x.grad))\n",
    "print(\"Gradient of y is: \" + str(y.grad))\n",
    "print(\"Gradient of z is: \" + str(z.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b17ae00f3c0042c59afd06b74d14d867",
    "deepnote_cell_type": "markdown",
    "id": "-ssM9jMBbS1c"
   },
   "source": [
    "Ahora calculemos los gradientes para la función descrita en la imagen Graph1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": "4cb3e55243cf430a91f0703983052704",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 68,
    "execution_start": 1679001707990,
    "id": "xuyomr_DZsOK",
    "source_hash": "f7d689af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of x is: tensor([[-1.8567e-05, -1.9381e-05,  5.4878e-06,  ...,  4.9478e-05,\n",
      "         -2.0345e-06, -2.3452e-05],\n",
      "        [-5.2718e-05,  5.7794e-06, -2.6836e-05,  ...,  3.2787e-05,\n",
      "          5.2222e-05,  1.2415e-05],\n",
      "        [ 4.4596e-05, -9.0558e-06,  4.2765e-05,  ..., -2.1597e-05,\n",
      "          3.8958e-06, -2.6026e-06],\n",
      "        ...,\n",
      "        [-2.9831e-05, -3.8455e-05,  3.3486e-05,  ...,  7.5862e-05,\n",
      "          3.1390e-05,  1.5514e-05],\n",
      "        [ 2.7116e-05, -8.2430e-06, -5.5107e-05,  ...,  2.1600e-05,\n",
      "          1.2638e-05,  2.2462e-05],\n",
      "        [-6.2203e-05, -2.9038e-05,  3.0074e-05,  ..., -2.3313e-05,\n",
      "         -1.1898e-05, -7.0464e-05]])\n",
      "Gradient of y is: tensor([[-1.2102e-05,  1.1553e-05, -3.3145e-05,  ...,  3.5507e-06,\n",
      "         -2.4746e-05, -2.7092e-05],\n",
      "        [-4.8961e-05, -7.3615e-05,  2.1817e-07,  ..., -3.5733e-05,\n",
      "         -8.2058e-05,  1.1743e-05],\n",
      "        [-7.9524e-06,  4.5697e-05, -2.2145e-05,  ...,  3.3530e-05,\n",
      "         -6.6698e-05,  3.4846e-05],\n",
      "        ...,\n",
      "        [ 2.6057e-05, -6.4647e-05, -2.8485e-05,  ...,  5.1447e-06,\n",
      "          1.7314e-05, -8.6044e-05],\n",
      "        [ 1.7146e-05,  3.5903e-06,  1.0330e-05,  ...,  4.3030e-06,\n",
      "          1.5163e-05, -2.0932e-05],\n",
      "        [-4.8407e-05, -1.1403e-05,  1.4185e-06,  ..., -3.0274e-05,\n",
      "         -7.7890e-06,  3.1676e-07]])\n",
      "Gradient of z is: tensor([[ 5.3944e-05,  1.8325e-05, -4.4736e-05,  ...,  1.3481e-05,\n",
      "          8.2138e-06,  1.6291e-05],\n",
      "        [ 4.2600e-05,  2.1904e-05,  1.8345e-05,  ...,  6.0892e-07,\n",
      "          5.3267e-05, -4.2060e-05],\n",
      "        [-1.8452e-05,  3.8326e-06,  3.9972e-05,  ..., -4.2842e-05,\n",
      "         -4.6942e-05,  1.7686e-05],\n",
      "        ...,\n",
      "        [ 4.8472e-06,  1.7113e-06,  8.5893e-06,  ..., -3.3728e-05,\n",
      "         -6.5533e-06, -3.9335e-05],\n",
      "        [-6.3654e-05,  3.3739e-05,  4.4320e-06,  ..., -5.2185e-05,\n",
      "         -2.0849e-05, -2.1406e-05],\n",
      "        [-5.3458e-06,  2.2086e-05, -3.8171e-06,  ...,  1.4859e-05,\n",
      "          1.1624e-05,  1.1886e-05]])\n"
     ]
    }
   ],
   "source": [
    "# Initializar x,y,z como tensores aleatorios de tamaño (1000,100)\n",
    "x = torch.randn((1000, 1000), requires_grad = True, dtype=torch.float32)\n",
    "y = torch.randn((1000, 1000), requires_grad = True, dtype=torch.float32)\n",
    "z = torch.randn((1000, 1000), requires_grad = True, dtype=torch.float32)\n",
    "\n",
    "# Multiplicar los tensores x con y\n",
    "q = x.matmul(y)\n",
    "\n",
    "# Multiplicar componente a componente los tensores z con q\n",
    "f = q * z\n",
    "\n",
    "mean_f = torch.mean(f)\n",
    "\n",
    "# Calcular los gradientes\n",
    "mean_f.backward()\n",
    "print(\"Gradient of x is: \" + str(x.grad))\n",
    "print(\"Gradient of y is: \" + str(y.grad))\n",
    "print(\"Gradient of z is: \" + str(z.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "daf0852b73a640cea1a223f41a6ec9b4",
    "deepnote_cell_type": "markdown",
    "id": "8h8oiEp3eWTU"
   },
   "source": [
    "### Construcción de redes neuronales con Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "982fe80476f145ceb9e92bea8e664eba",
    "deepnote_cell_type": "markdown",
    "id": "DEH8zLXhazmN"
   },
   "source": [
    "Construimos una red neuronal en Pytorch de forma *manual*. la entrada serán imágenes de tamaño (28,28). Es decir contienen pixeles de 784 pixeles. \n",
    "La red contendrá una capa de entrada, una capa oculta con 200 unidades y una capa de salida con 10 categorías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": "c03da4f07a4e40849fb579a1b5800516",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1679001712345,
    "id": "uXjt0ggwGWbb",
    "outputId": "0acd0bcf-8784-4dba-bddc-b1107d400790",
    "source_hash": "9d1c1205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18543.3984, 19991.0430, 20464.4238, 21341.3340, 21070.0410, 20811.6660,\n",
      "        20753.3906, 21722.1191, 20250.8242, 19208.4355])\n"
     ]
    }
   ],
   "source": [
    "input_layer=torch.rand(784)\n",
    "\n",
    "# Inicializar los pesos de la red neuronal\n",
    "weight_1 = torch.rand(784, 200)\n",
    "weight_2 = torch.rand(200, 10)\n",
    "\n",
    "# Multiplicar la capa de entrada con el peso 1\n",
    "hidden_1 = torch.matmul(input_layer, weight_1)\n",
    "\n",
    "# Multiplicar la capa oculta con el peso 2\n",
    "output_layer = torch.matmul(hidden_1, weight_2)\n",
    "print(output_layer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a5071efc12e04c6db0508c2a89df372b",
    "deepnote_cell_type": "markdown",
    "id": "54kg7I1udw5p"
   },
   "source": [
    "Ahora construimos la misma rede neuronal pero utilizando los módulos de Pytorch. (Ver sección *The model* del cuaderno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": "dccd7e199c6f4150aae305557432883f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1679001716944,
    "id": "7bb9bFrzHBhT",
    "source_hash": "b8688a5"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Inicializar las dos capas lineales \n",
    "        self.fc1 = nn.Linear(784, 200)\n",
    "        self.fc2 = nn.Linear(200, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "      \n",
    "        # Usar las capas inicializadas y devolver x\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d93881f46d9347f2be965f65de51e2a0",
    "deepnote_cell_type": "markdown",
    "id": "mM-RqOEQfjb4"
   },
   "source": [
    "Construyamos la red neuronal en la gráfica NN1 dada ede forma *manual*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": "e51ac7c43b044073b8ce45e0bb4ceadb",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1679002271029,
    "id": "y4CXMDaaHjym",
    "source_hash": "5a0b7241"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.3589, 0.1142, 1.7133, 1.8927])\n"
     ]
    }
   ],
   "source": [
    "# Crear tensor aleatorio como capa de entrada\n",
    "input_layer= torch.rand(4)\n",
    "\n",
    "# Crear matrices de pesos\n",
    "weight_1= torch.rand(4,4)\n",
    "weight_2= torch.rand(4,4)\n",
    "weight_3= torch.rand(4,4)\n",
    "\n",
    "# Calcular la primera y segunda capa oculta\n",
    "\n",
    "hidden_1 = torch.matmul(input_layer, weight_1)\n",
    "hidden_2 = torch.matmul(hidden_1, weight_2)\n",
    "\n",
    "# Imprimir la salida\n",
    "print(torch.matmul(hidden_2,weight_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "46e18ff16a8a4dd39a160a993b12f90d",
    "deepnote_cell_type": "markdown",
    "id": "iSbwtRcygzpw"
   },
   "source": [
    "La anterior era una red neuronal con 2 capas ocultas ocultas en donde no se aplica ninguna función no-lineal. Veamos que ésta se puede construir con una sola capa oculta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": "b1425642b3a7474497af1beb2c8b50c2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1679002808673,
    "id": "HUVgFxvSgvHc",
    "source_hash": "4ae0ddb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.3589, 0.1142, 1.7133, 1.8927])\n"
     ]
    }
   ],
   "source": [
    "# Calcular la compuesta de las matrices de pesos\n",
    "weight_composed_1 = torch.matmul(weight_1,weight_2)\n",
    "weight = torch.matmul(weight_composed_1,weight_3)\n",
    "\n",
    "# Multiplicar la capa de entrada por weight e imprimir\n",
    "print(torch.matmul(input_layer, weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4d3e580f23e8443dbd534126ab2d3d47",
    "deepnote_cell_type": "markdown",
    "id": "hLcs6NtUlo-f"
   },
   "source": [
    "## Entrenamiendo de una red neuronal para reconocimiento de dígitos (MNIST Dataset)\n",
    "### Preparar los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b88906498c5a4ee38656841585fae281",
    "deepnote_cell_type": "markdown",
    "id": "jZkIa4FSl9h-"
   },
   "source": [
    "Para preparar los datos primero creamos un parámetro *transform* para transformarlos. Haremos dos cosas:\n",
    "- Transformar las imágenes del MNIST Dataset a tensores para poder alimentar la red neuronal. Esto lo hacemos con el método ToTensor.\n",
    "- Por otro lado, debemos normalizarlos con respecto a una media y variaza. Esto lo hacemos con el método Normalize. En este caso usaremos una media de 0.1307 y varianza de 0.3081. (Tenga en cuenta que en el MNIST Dataset los pixeles son en escala de grises, por lo cual sólo tienen un canal de código de color.)\n",
    "\n",
    "Para componer ambas transformaciones (Convertir a tensor y normalizar) usamos transforms.Compose ver [AQUÍ](https://www.programcreek.com/python/example/104832/torchvision.transforms.Compose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": "839fbe239e7647e58499bec22db0f9eb",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7,
    "execution_start": 1679002841248,
    "id": "lg4S9bKLS2vp",
    "source_hash": "43d96932"
   },
   "outputs": [],
   "source": [
    "# Transformar los datos a tensores y normalizarlos \n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "\t\t\t\t\t\t\t\ttransforms.Normalize((0.1307), ((0.3081)))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "364c01beb91844b09028bc7692024240",
    "deepnote_cell_type": "markdown",
    "id": "4of_hxAcrdpi"
   },
   "source": [
    "Ahora definimos el conjunto de entrenamiento y testeo. Torchvision permite cargar datasets conocidos para visión como el MNIST. \n",
    "Para entender y completar los parámetros ver [AQUÍ](https://pytorch.org/vision/main/generated/torchvision.datasets.MNIST.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": "065c937ee9b24e8e9ff9a6b63f92c4f2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 115,
    "execution_start": 1679002842616,
    "id": "61nyqG7wrSec",
    "source_hash": "a3694a84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 9912422/9912422 [00:00<00:00, 10237156.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/MNIST/raw/train-images-idx3-ubyte.gz to mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 15281404.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/MNIST/raw/train-labels-idx1-ubyte.gz to mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 1648877/1648877 [00:00<00:00, 6403146.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 3662858.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Preparar el training set y testing set\n",
    "trainset = torchvision.datasets.MNIST('mnist', train=True, \n",
    "\t\t\t\t\t\t\t\t\t  download=True, transform=transform)\n",
    "                                      \n",
    "testset = torchvision.datasets.MNIST('mnist', train=False, \n",
    "\t\t\t\t\t\t\t\t\t  download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8b331dabb74441d18e224c0840c77310",
    "deepnote_cell_type": "markdown",
    "id": "JOxpKc2StPB6"
   },
   "source": [
    "El método DataLoader hace parte de torch.utils.data y permite cargar los datos por lotes de un tamaño definido. Para entender los parámetros ver [AQUÍ](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader).\n",
    "Preparar los datos para entrenamiento y testeo de manera que se procesen 32 imágenes cada vez y se barajen cada vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": "601d8bb107144c4dae858ab62b64144e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1679002844072,
    "id": "DCJcCLjytI5_",
    "source_hash": "6da59061"
   },
   "outputs": [],
   "source": [
    "# Preparar training loader y testing loader. \n",
    "# Usar los parámetros dataset, batch_size, shuffle y num_workers.\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, \n",
    "                                          shuffle=True, num_workers=0)\n",
    "                                          \n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, \n",
    "                                         shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0126f7498f3d4b14979c21f697e6a176",
    "deepnote_cell_type": "markdown",
    "id": "z2ZNcnMLvjQr"
   },
   "source": [
    "Construya una clase para una red neuronal que será usada para entrenar el MNIST dataset. El dataset contiene imagenes de dimensiones (28,28,2), así que usted deducirá el tamaño de la capa de entrada. Para las calas ocultas use 200 unidades y para la capa de salida 10 unidades (una por cada categoría (Dígitos del 0 al 9)).\n",
    "Como función de activación use Relu de manera funcional (nn.Functional ya está importado como F).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "cell_id": "f01982a64b6143a4aa5f4c5fbbddabdd",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1679002845269,
    "id": "-v_2od5dVx33",
    "source_hash": "db69831c"
   },
   "outputs": [],
   "source": [
    "# Define the class Net\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):    \n",
    "    \t# Define all the parameters of the net\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 200)\n",
    "        self.fc2 = nn.Linear(200, 10)\n",
    "\n",
    "    def forward(self, x):   \n",
    "    \t# Do the forward pas\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4d79f0da5b6e47919c9b23c9eecbe206",
    "deepnote_cell_type": "markdown",
    "id": "hW1FzRFVvGFU"
   },
   "source": [
    "###Entrenamiento del modelo\n",
    "\n",
    "Por favor analice cuidadosamente el siguiente código, hasta que quede claro los pasos de entrenamiento y evaluación del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e4c7b4db35e84c29be244cb9290846a0",
    "deepnote_cell_type": "markdown",
    "id": "P4Hd2AAqwSRX"
   },
   "source": [
    "En primer lugar, revisemos si estamos trabajando en GPU. De lo contrario debemos cambiar el tipo de entorno de ejecución en el menú de Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "cell_id": "eb70d43e73004f4ca5947ce377769226",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1679002846548,
    "id": "3lSdEYQTvFFX",
    "source_hash": "9694620a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the GPU available? True\n"
     ]
    }
   ],
   "source": [
    "gpu_avail = torch.cuda.is_available()\n",
    "print(f\"Is the GPU available? {gpu_avail}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7df4db14ea7347c1a372573054e17981",
    "deepnote_cell_type": "markdown",
    "id": "uhlAJDQNcJRD"
   },
   "source": [
    "Le daremos nombre a nuestro dispositivo GPU, al cual debemos transferir nuesto modelo y los datos a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "cell_id": "5d4ab8b0535d46af8af36fe8725aefb1",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1679002847537,
    "id": "TIy4UMIGX72j",
    "source_hash": "c1127845"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7dd2e1f5c24b434abecbc7db73e712b0",
    "deepnote_cell_type": "markdown",
    "id": "PrDZ6975w0SZ"
   },
   "source": [
    "Definimos nuestro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "cell_id": "361bcd9030154e6481b08ac3527646ed",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1679002849861,
    "id": "7yVvkS2lv2eU",
    "source_hash": "5758b227"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=200, bias=True)\n",
      "  (fc2): Linear(in_features=200, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "afdffb8cbe0a45139a632c22b6ea6dbc",
    "deepnote_cell_type": "markdown",
    "id": "T42H97fqw7O0"
   },
   "source": [
    "Empujamos nuestro modelo al dispositivo GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "cell_id": "8a1f533e6160492198f0d078d27a0929",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1679002851635,
    "id": "jOvAocBcv6DD",
    "source_hash": "7227c2e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=200, bias=True)\n",
       "  (fc2): Linear(in_features=200, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Push model to device. Has to be only done once\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "39ea4ab1c62646768cfd37bb3ff72177",
    "deepnote_cell_type": "markdown",
    "id": "M0kY1SvaxFep"
   },
   "source": [
    "Definimos el ptimizador y la función de costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "cell_id": "d15da99cd4c444cd9b8fdcac47433721",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1679002852351,
    "id": "1GVA5xRAv98M",
    "source_hash": "eb6e6a61"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001) # descenso de gradiente\n",
    "loss_module = nn.CrossEntropyLoss()  #función de costo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6007247aef3a49b7854ac08a163ba713",
    "deepnote_cell_type": "markdown",
    "id": "WGIHuKHYxJIh"
   },
   "source": [
    "Entrenamos el modelo, siguiendo los 5 pasos vistos en clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "cell_id": "abfa0c0685324ccd8fcd56e3022363db",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1679002853129,
    "id": "Z7e83caQwBdJ",
    "source_hash": "d9ad62ae"
   },
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, testloader, loss_module, num_epochs=1):\n",
    "    # Set model to train mode\n",
    "    model.train() \n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for data_inputs, data_labels in testloader:\n",
    "            data_inputs = data_inputs.view(-1, 28 * 28)\n",
    "            ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
    "            data_inputs = data_inputs.to(device)\n",
    "            data_labels = data_labels.to(device)\n",
    "\n",
    "           \n",
    "            \n",
    "            ## Step 2: Run the model on the input data\n",
    "            preds = model(data_inputs)\n",
    "            preds = preds.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
    "            \n",
    "            ## Step 3: Calculate the loss\n",
    "            loss = loss_module(preds, data_labels)\n",
    "            \n",
    "            ## Step 4: Perform backpropagation\n",
    "            # Before calculating the gradients, we need to ensure that they are all zero. \n",
    "            # The gradients would not be overwritten, but actually added to the existing ones.\n",
    "            optimizer.zero_grad() \n",
    "            # Perform backpropagation\n",
    "            loss.backward()\n",
    "            \n",
    "            ## Step 5: Update the parameters\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "cell_id": "a68f2a5cd2494ff8b70db602e1592242",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 148,
    "execution_start": 1679002855619,
    "id": "OxY1U-kkwFIW",
    "source_hash": "1dc890c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0757a85ec68d4f09a2890efb56a0ac41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(model, optimizer, trainloader, loss_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e08864028896407dac383f7555556dd0",
    "deepnote_cell_type": "markdown",
    "id": "86WV34CqcfkM"
   },
   "source": [
    "A continuación evaluaremos el desempeño del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "cell_id": "9503cc23464b4d38ad7df8c681be1bd3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 88,
    "execution_start": 1679002858785,
    "id": "KD6Z_tcOcxjI",
    "source_hash": "bf44558f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing set accuracy of the network is: 86 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total, correct =0,0\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    \n",
    "    # Put each image into a vector\n",
    "    inputs = inputs.view(-1, 784)\n",
    "    \n",
    "    # Do the forward pass and get the predictions\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    _, outputs = torch.max(outputs.data, 1) #mayor valor entre los dígitos.\n",
    "    total += labels.size(0)\n",
    "    correct += (outputs == labels).sum().item()\n",
    "print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cell_id": "cd43cea53e0f4be69a35c41d5b2db132",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "b623e53d",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=36d88c6c-6319-49ce-a935-dcbc7870232a' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "41acc49281824dd48c9fb687d4930dd9",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
