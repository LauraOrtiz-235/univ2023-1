{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5VUaJXwjAX4"
   },
   "source": [
    "# Taller 1: Regresión lineal, Ridge y Lasso\n",
    "**Nombres:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibE1PgK4IGiF"
   },
   "source": [
    "En este taller analizaremos métodos de regresión lineal para el conjunto de datos [Hitters](https://www.kaggle.com/datasets/floser/hitters). Cada registro corresponde a un jugador de baseball. Las variables son registros como cantidad de *home runs* o número de años en las ligas mayores. La variable objetivo es el salario de dicho jugador. \n",
    "Usaremos regresión de Ridge y Lasso y las compararemos. \n",
    "\n",
    "- El taller consiste en realizar todas las tareas señaladas con **TO_DO**. \n",
    "\n",
    "- Se puede realizar de forma individual o en parejas.\n",
    "\n",
    "- Subir el cuaderno en dos formatos : 1. En formato .ipynb  2. En formato .html.\n",
    "- Subirlo al aula a más tardar el miércoles 15 de ferbero.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mnPPGc-kv2gW"
   },
   "outputs": [],
   "source": [
    "#importar paquetes\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XnKq_XsE24O0"
   },
   "outputs": [],
   "source": [
    "#Evitar la impresión de warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MnY7M1vkav9"
   },
   "source": [
    "En primer lugar, leemos el conjunto de datos e imprimimos la información sobre sus columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hn49Fea4sqPM"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Hitters.csv').dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DFZ_n8uHnTNN"
   },
   "outputs": [],
   "source": [
    "#TO_DO 1: Codificar las 3 variables categóricas como variables Dummy (usar por ejemplo el\n",
    "#método get_dummies de Pandas). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Lt_zZfLs78W"
   },
   "outputs": [],
   "source": [
    "#Verificar la codificación anterior\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uAwIeNpdtID_"
   },
   "outputs": [],
   "source": [
    "# Definimos la columna y, correspondiente a la variable objetivo.\n",
    "y = df.Salary\n",
    "\n",
    "#TO_DO 2:\n",
    "#Eliminar la columna con la variable dependiente (Salary) y de ser necesario, las columnas originales para las que se crearon\n",
    "#variables dummy. Dar a la nueva tabla de atributos el nombre X (mayúscula).\n",
    "\n",
    "\n",
    "#Verificar lo anterior\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cdjFZR9lWGS"
   },
   "source": [
    "Vamos a generar valores de Lambda equidistantes para experimentar sobre un intervalo. Estos valores se encuentran entre 10^(-2) y 10^10. Experimentaremos con 100 valores distintos de lambda. Para esto usamos *linspace* de Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k7REJ95dtiuL"
   },
   "outputs": [],
   "source": [
    "# Creamos una lista con posibles valores para el parámetro Lambda para los algoritmos Ridge y Lasso\n",
    "lambdas = 10**np.linspace(10,-2,100)\n",
    "lambdas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMkdjJinqgam"
   },
   "source": [
    "Vamos a usar el algoritmo de Ridge de SKlearn para hacer regresión con los diferentes valores del parámetro Lambda, de manera que podamos realizar algunas observaciones y comparaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9N3z07Wtvmf"
   },
   "outputs": [],
   "source": [
    "# Aplicamos el algoritmo Ridge de SKlearn para los diferentes valores de Lambda definidos\n",
    "# en la celda anterior. Guardar los vectores obtenidos de parámetros en la lista coefs.\n",
    "ridge = Ridge(normalize = True)\n",
    "coefs = []\n",
    "\n",
    "for a in lambdas:\n",
    "    ridge.set_params(alpha = a)\n",
    "    ridge.fit(X, y)\n",
    "    coefs.append(ridge.coef_)\n",
    "#Imprimir las dimensiones de la matriz coef.   \n",
    "np.shape(coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1t0wbe1q12G"
   },
   "source": [
    "Usamos los arreglos *lambdas* y *coefs* para comparar los resultados de la regresión Ridge para diferentes valores del parámetro Lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HsHxVKALuQgA"
   },
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.plot(lambdas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZoWHrSPPJCyG"
   },
   "source": [
    "TO_DO 3: Hallar el coeficiente de las variables Hits Runs y Walks, arrojado por el algoritmo Ridge, para 3 lambdas distintos.\n",
    "Ejemplo: \"Para lambda=3.06795364e+00, el coeficiente de Hits es (valor), el coeficiente de Runs es (valor) y el coeficiente de Walks es (valor).\"\n",
    "\n",
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNB_1iWSs0x_"
   },
   "source": [
    "A continuación separamos el conjunto de datos en conjunto de Entrenamiento y Testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZT6Ulnl9ubYn"
   },
   "outputs": [],
   "source": [
    "#TO_DO 4: \n",
    "#Escoger random_sate = 0. Y partir el conjunto de datos en Entrenamiento y Testeo, con porcentaje de Testeo de 20%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VY6_5sQfvn1O"
   },
   "source": [
    "Apliquemos el algoritmo de regresión lineal de SKLearn a éste conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D2bSIcULDiF5"
   },
   "outputs": [],
   "source": [
    "#TO_DO 5: Aplicar el algoritmo de regresión lineal de SKLearn a éste conjunto de datos e\n",
    "# imprimir su coeficiente de determinación R^2 (score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8aJWiIxKu29p"
   },
   "source": [
    "TO_DO 6: Cuáles son los valores de los parámetros en el modelo lineal obtenido? (Pista: En el taller anterior eran la pendiente y el punto de corte.) Cuál valor corresponde con cuál variable en el Dataset?\n",
    "\n",
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOipPDgdwHIj"
   },
   "source": [
    "## Regresión Ridge\n",
    "Ahora apliquemos Regresión de Ridge para algunos valores de lambda. En primer lugar usemos Lambda=4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FkxCVV82u0MH"
   },
   "outputs": [],
   "source": [
    "#Modelo de regresión de Ridge para Lambda=4\n",
    "# Note el uso del parámetro normalize=True\n",
    "ridge = Ridge(alpha = 4, normalize = True)\n",
    "ridge.fit(X_train, y_train)             # Entrenar una regresión de Ridge para el conjunto de entrenamiento.\n",
    "pred = ridge.predict(X_test)           # Uso del modelo para predecir el conjunto de Testeo\n",
    "print(pd.Series(ridge.coef_, index = X.columns)) # Imprimir los coeficientes del modelo\n",
    "print(mean_squared_error(y_test, pred))          # Imprimit el error de mínimos cuadrados MSE\n",
    "print(ridge.score(X_test, y_test))         #Imprimir el coeficiente de determinación R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jFATExWKu3ZX"
   },
   "outputs": [],
   "source": [
    "#TO_DO 7 Hacer regresión Ridge para lambda=10^10. Imprimir los coeficientes obtenidos y el error MSE\n",
    "# Usar el parámetro normalize=True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hG9rLSeBypmX"
   },
   "source": [
    "TO_DO 8: Cuál debería ser el coeficiente de determinación R^2 al asignar Lambda=0? Justifique y compruebe en la siguiente celda.\n",
    "\n",
    "**Respuesta y justificación:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cPKuNNqivH8v"
   },
   "outputs": [],
   "source": [
    "# TO_DO 9 Verifique su respuesta anterior.\n",
    "# Usar el parámetro normalize=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISu__2uNvbcp"
   },
   "outputs": [],
   "source": [
    "# con RidgeCV de SKLearn hacer cross validation con la lista de Lambdas y normalize True\n",
    "# Imprimir el alpha optimo. Note que usamos el parametro normalize=True\n",
    "ridgecv = RidgeCV(alphas = lambdas, normalize = True)\n",
    "ridgecv.fit(X_train, y_train)\n",
    "ridgecv.alpha_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-r72ay2gvjpo"
   },
   "outputs": [],
   "source": [
    "#TO_DO 10 Con el alpha optimo hallado arriba, calcular los coeficientes(parámetros),\n",
    "# el error cuadrático MSE y el coeficiente de determinación R^2 en el conjunto de Testeo.\n",
    "# Usar el parámetro normalize=True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1tTtE2w1OcF"
   },
   "source": [
    "## Regresión Lasso\n",
    "Ahora aplicaremos regresión Lasso a éste conjunto de datos. Para esto, en primero lugar encontremos el valor óptimo de Lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_Acv6lawBDT"
   },
   "outputs": [],
   "source": [
    "# TO_DO 11 Determinar el valor óptimo de Lambda mediante corss-validation\n",
    "## Usar el parámetro normalize=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5dO8Eg-EwXND"
   },
   "outputs": [],
   "source": [
    "# TO_DO 12 Aplicar regresión de Lasso al conjunto de datos, usando el valor de Lambda encontrado arriba\n",
    "# Usar el parámetro normalize=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mBX9-ongw1XA"
   },
   "outputs": [],
   "source": [
    "#Imprimir los coeficientes de la misma forma que en Ridge.\n",
    "pd.Series(lasso.coef_, index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JdjVTuwhxBf3"
   },
   "outputs": [],
   "source": [
    "#Imprimir el score (R^2)\n",
    "print(lassocv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xF5UUEhx5r1_"
   },
   "source": [
    "TO_DO 13: Escriba sus conclusiones acerca de los diferentes modelos obtenidos y sus métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dU0UZlGKqPiq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
