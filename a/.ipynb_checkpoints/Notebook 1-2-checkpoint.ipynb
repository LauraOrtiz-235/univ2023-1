{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9e75e0d3292f425f9e178c7502b651f0",
    "deepnote_app_coordinates": {
     "h": 22,
     "w": 12,
     "x": 0,
     "y": 1
    },
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<img src=\"https://s3.amazonaws.com/media-p.slid.es/uploads/1485763/images/9060062/Header.png\" alt=\"Header\" style=\"width: 800px;\"/>\n",
    "\n",
    "# Aprendizaje Autom谩tico de M谩quina\n",
    "\n",
    "Yiby Karolina Morales Pinto\n",
    "\n",
    "```\n",
    "Integrantes\n",
    "\n",
    "Laura Sof铆a Ortiz Arcos\n",
    "David Santiago Fl贸rez Alsina\n",
    "```    \n",
    "\n",
    "<hr> </hr>\n",
    "\n",
    "Abril 27, 2023\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "73701962355542cc835a14a30fd90981",
    "deepnote_app_coordinates": {
     "h": 28,
     "w": 12,
     "x": 0,
     "y": 24
    },
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Antecedentes\n",
    "\n",
    "_**Opcional:**_ Nuestra motivaci贸n para trabajar este problema es utilizar unos datos que recolectamos aproximadamente hace un a帽o en el laboratorio Bardeen en la primera edici贸n del proyecto de emprendimiento ___Maticas___.\n",
    "\n",
    "\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"./albahaca_maticas_v3_heavy.png\" alt=\"Header\" style=\"width: 400px;\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "***Maticas*** surge de ver c贸mo en *Colombia* se tratan de generar soluciones para ayudar al agricultor y permitirle ser m谩s productivo, en un tiempo en el que se habla mucho de reformas agrarias y distribuci贸n de tierras, pero el debate no inicia oficialmente y menos el planteamiento de una soluci贸n y su implementaci贸n, mientras que a la vez las nuevas generaciones de personas que nacen en estas zonas rurales ya no quieren dedicarse a los campos ya que la ven como una actividad muy exaustiva y con poco retorno econ贸mico en comparaci贸n con lo que ofrece la ciudad. *Maticas* busca que a trav茅s de la tecnolog铆a se le pueda dar soluci贸n a parte del problema del agro que el estado a煤n no ha solucionado.\n",
    "\n",
    "\n",
    "El inicio y actual prop贸sito ***Maticas*** es ayudar al agricultor a *esforzarse menos* en su trabajo, obteniendo *mejores resultados*, permitiendo a todos los consumidores el tener *m谩s variedad de plantas, de mejor calidad y mejor precio* para alimentarnos. Nuestro objetivo no solo busca fortalecer el agro en el sector rural, sino tambi茅n en el urbarno, a trav茅s de huertas urbanas automatizadas con hidropon铆a que se puedan ubicar en distintos espacios y empresas.\n",
    "\n",
    "En un futuro pr贸ximo buscamos incorporar inteligencia artificial para ayudar al agricultor a tomar acciones que protejan su cultivo, si por ejemplo pudieramos detectar que dentro de 48 horas va a haber una helada, se podr铆an tomar ciertas acciones que mitiguen los efectos sobre el cultivo, por ejemplo. Lo que buscamos con este proyecto es acercarnos un poco a esto.\n",
    "\n",
    "Hay trabajos que hacen labores similares de predicci贸n muchos de ellos usan redes neuronales recurrentes, sin embargo nosotros queremos probar una aproximaci贸n desde las redes neuronales sencillas y la extracci贸n de caracter铆sisticas temporales, de nuestras se帽ales.\n",
    "\n",
    "links para hablar: \n",
    "\n",
    "- https://repositorio.uniandes.edu.co/bitstream/handle/1992/45458/u827540.pdf?sequence=1 \n",
    "\n",
    "- https://upcommons.upc.edu/bitstream/handle/2117/108387/memoria-tfm-federico-aguilar-calvo.pdf?sequence=1&isAllowed=y\n",
    "\n",
    "- http://somim.org.mx/memorias/memorias2020/articulos/A4_6.pdf\n",
    "\n",
    "- https://oa.upm.es/11206/1/MARIA_GUADALUPE_CORTINA_JANUCHS.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2ac47b9745b64b33b702f43c43ec9160",
    "deepnote_app_coordinates": {
     "h": 10,
     "w": 12,
     "x": 0,
     "y": 53
    },
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Definici贸n del problema\n",
    "\n",
    "Se describe claramente el problema que se resolver谩. El problema debe estar bien definido, debe ser cuantificable y medible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "79fe9463d5a4469ca04b5ec932f8f562",
    "deepnote_app_coordinates": {
     "h": 9,
     "w": 12,
     "x": 0,
     "y": 64
    },
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "_Nos planteamos solucionar la problem谩tica de predecir humedad y temperatura ambiental usando redes neuronales y tensorflow, lo haremos con predicciones para 10 min, 15 min, 30 min y 60 min en el futuro_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "85c8a89dd8e1425a927a9f5c2a4f75d2",
    "deepnote_app_coordinates": {
     "h": 11,
     "w": 12,
     "x": 0,
     "y": 74
    },
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Descripci贸n de la soluci贸n\n",
    "\n",
    "Descripci贸n de c贸mo se abordar谩 el problema. La estrategia planteada es aplicable al proyecto y apropiada para los datos dados. Adicionalmente, la soluci贸n es cuantificable y medible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "47ff617a6a58419ebd0152a2bcc82ce0",
    "deepnote_app_coordinates": {
     "h": 8,
     "w": 12,
     "x": 0,
     "y": 86
    },
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "_Construir una red neuronal predictiva para los periodos de tiempo seleccionados, probaremos distintas arquitecturas y funciones de activaci贸n, para encontrar la mejor red de todas._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "129e577f9e3b4513836be5df0f343c40",
    "deepnote_app_coordinates": {
     "h": 10,
     "w": 12,
     "x": 0,
     "y": 95
    },
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Datos\n",
    "\n",
    "El dataset a usar en el proyecto debe ser descrito detalladamente. Informaci贸n acerca de d贸nde se obtuvo el dataset y sus caracter铆sticas, debe ser inclu铆da. As铆 como toda referencia utilizada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e12de02cde9542adb32812d53f933b53",
    "deepnote_app_coordinates": {
     "h": 12,
     "w": 12,
     "x": 0,
     "y": 106
    },
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Nuestro dataset se compone de las siguientes mediciones:\n",
    "- Luz (lux). \n",
    "- Humedad relativa (%). \n",
    "- Tempertura ambiental (掳C). \n",
    "- Presi贸n atmosf茅rica (mmHg).\n",
    "\n",
    "Cada medici贸n tiene un timestamp asociado que nos indica el instante en el que se midi贸."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bd797aa78e45449aa8d649210917f051",
    "deepnote_app_coordinates": {
     "h": 11,
     "w": 12,
     "x": 0,
     "y": 119
    },
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Modelo de referencia\n",
    "\n",
    "Se debe hacer un experimento preliminar con un primer algoritmo, puede ser simple. Esto con el fin de obtener una primera aproximaci贸n al problema, la cual se deber谩 mejorar durante el proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "65fed2f6a8fc4486905fb3974eda9bd5",
    "deepnote_app_coordinates": {
     "h": 18,
     "w": 12,
     "x": 0,
     "y": 131
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9558,
    "execution_start": 1683840309384,
    "source_hash": "90981e97"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 18:20:09.574475: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-13 18:20:09.735368: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-13 18:20:09.736540: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-13 18:20:11.153039: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import datetime          as dt\n",
    "import pandas            as pd\n",
    "import tensorflow        as tf\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn                 import preprocessing\n",
    "from tensorflow              import keras\n",
    "from datetime                import timedelta\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "592560f4bab944c7b69231cea8d02c50",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Preprocesamiento de los datos\n",
    "\n",
    "$$(1)$$ Indexamos cada dato con su timestamp en lugar de un 铆ndice num茅rico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "fcd965cbbe334232adf683a9169052e4",
    "deepnote_app_coordinates": {
     "h": 15,
     "w": 12,
     "x": 0,
     "y": 150
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10,
    "execution_start": 1683840318938,
    "source_hash": "d4fbddc7"
   },
   "outputs": [],
   "source": [
    "def separate_timestamp(df):\n",
    "    \"\"\"\n",
    "    Converts the 'time' column in the input dataframe to a pandas datetime format.\n",
    "    \n",
    "    INPUT:\n",
    "        - df: A pandas DataFrame with a 'time' column\n",
    "    \n",
    "    OUTPUT:\n",
    "        - pd.DataFrame: A copy of the input dataframe with the 'time' column converted to pandas datetime format\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert the 'time' column to a pandas datetime format\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "    # Return the modified dataframe\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5a73402a9daa4062a4ee4f0d5229b1df",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "$$(2)$$ Extraemos algunas caracter铆sticas en intervalos de tiempo seleccionados por nosotros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "063d0cd639294844886ecf3fa8962def",
    "deepnote_app_coordinates": {
     "h": 28,
     "w": 12,
     "x": 0,
     "y": 166
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 26,
    "execution_start": 1683840318961,
    "source_hash": "bbdd5624"
   },
   "outputs": [],
   "source": [
    "\n",
    "def calculate_rolling_average(df: pd.DataFrame, N: list, var: str):\n",
    "    \"\"\"\n",
    "    Calculates rolling statistics of a specified variable for a given window size and adds them as new columns\n",
    "    to the input dataframe.\n",
    "    \n",
    "    Args:\n",
    "    - df (pandas DataFrame): input dataframe containing a column named 'time' and the variable of interest \n",
    "                             specified in the 'var' argument.\n",
    "    - N (list of integers):  list of window sizes (in minutes) for which to calculate rolling statistics.\n",
    "    - var (string):          name of the variable of interest for which to calculate rolling statistics.\n",
    "    \n",
    "    Returns:\n",
    "    - pandas DataFrame:      modified dataframe with new columns added for the rolling statistics.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set the 'time' column as the dataframe index\n",
    "    df.set_index('time', inplace=True)\n",
    "\n",
    "    # Calculate the rolling statistics of the 'var' column for each window size in the list N\n",
    "    for n in N:\n",
    "        rolling_average   = df[var].rolling(f'{n}min').mean()\n",
    "        rolling_variance  = df[var].rolling(f'{n}min').var()\n",
    "        rolling_minimum   = df[var].rolling(f'{n}min').min()\n",
    "        rolling_maximum   = df[var].rolling(f'{n}min').max()\n",
    "\n",
    "        # Add the rolling statistics as new columns to the dataframe, filling NaN values with the next valid value\n",
    "        df[f'avg_{n}min']  = rolling_average.bfill()\n",
    "        df[f'var_{n}min']  = rolling_variance.bfill()\n",
    "        df[f'max_{n}min']  = rolling_maximum.bfill()\n",
    "        df[f'min_{n}min']  = rolling_minimum.bfill()\n",
    "\n",
    "    # Return the modified dataframe\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "d7abdfc3e6944f4db7397073f74eaa27",
    "deepnote_app_coordinates": {
     "h": 4,
     "w": 12,
     "x": 0,
     "y": 195
    },
    "deepnote_cell_type": "code",
    "deepnote_table_loading": false,
    "deepnote_table_state": {
     "filters": [],
     "pageIndex": 0,
     "pageSize": 10,
     "sortBy": []
    },
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 54,
    "execution_start": 1683840318990,
    "source_hash": "c356a434"
   },
   "outputs": [],
   "source": [
    "df = separate_timestamp( pd.read_csv('hum.csv') )\n",
    "features = calculate_rolling_average(df, [10, 15, 30, 60], 'hum_level')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ec0ff9fd310d47fba3c283611df10938",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "$$(3)$$ Escalamos nuestros datos para probar si nos dan mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "67054db6f99145d58cf4091964837ed5",
    "deepnote_app_coordinates": {
     "h": 25,
     "w": 12,
     "x": 0,
     "y": 200
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7,
    "execution_start": 1683840319057,
    "source_hash": "6145b3b4"
   },
   "outputs": [],
   "source": [
    "def data_scaling(data: pd.DataFrame,\n",
    "                 scaler: sklearn.preprocessing._data,\n",
    "                 scaling_columns     = [], \n",
    "                 not_scaling_columns = [], \n",
    "                 dropping = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Scales the specified columns in the input DataFrame using the given scaler object.\n",
    "    \n",
    "    INPUT:\n",
    "        - data:                Pandas DataFrame to be scaled\n",
    "        - scaler:              Scaler object from sklearn.preprocessing\n",
    "        - scaling_columns:     List of column names to scale\n",
    "        - not_scaling_columns: List of column names to not scale\n",
    "        \n",
    "    OUTPUT: \n",
    "        - pd.DataFrame:        A scaled copy of the input data with the specified columns scaled\n",
    "    \"\"\"\n",
    "\n",
    "    # if the user provided all the columns he wishes to scale \n",
    "    if scaling_columns:\n",
    "        data[scaling_columns] = scaler.fit_transform(data[scaling_columns].to_numpy())\n",
    "\n",
    "    # if user provided only the columns he doesn't want to scale\n",
    "    elif not_scaling_columns:\n",
    "        used_cols = data.columns.difference(not_scaling_columns)\n",
    "        data.loc[:, used_cols] = scaler.fit_transform(data.loc[:, used_cols].to_numpy())\n",
    "\n",
    "    else:\n",
    "        data.iloc[:] = scaler.fit_transform(data.iloc[:].to_numpy())\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "da5991782cbc4eb5a64ade448ee03435",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "$$(4)$$ Construimos la matrix $$Y$$ que es una lista de salidas que buscamos obtener con nuestra predicci贸n, donde cada fila tiene 4 columnas y cada una es el valor en 10, 15, 30 y 60 minutos en el futuro para la humedad relativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "66904c16fe59450da6bfbceae3dcfa0b",
    "deepnote_app_coordinates": {
     "h": 34,
     "w": 12,
     "x": 0,
     "y": 226
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 45,
    "execution_start": 1683840319066,
    "source_hash": "2eee4e5"
   },
   "outputs": [],
   "source": [
    "def find_future_measurement(data: pd.DataFrame,\n",
    "                            curr_measurement: pd.core.series.Series,\n",
    "                            prediction_var: str,\n",
    "                            N: list) -> tuple:\n",
    "    \"\"\"\n",
    "    Takes a complete dataframe (data) and a row of this dataframe (curr_measurement), and finds the future measurements \n",
    "    for a given list of time intervals (N).\n",
    "    \n",
    "    INPUT:\n",
    "        - data: A pandas DataFrame containing the measurement data\n",
    "        - curr_measurement: A pandas Series containing a single row (measurement) of the DataFrame (data)\n",
    "        - prediction_var: A string representing the name of the column containing the measurement to predict\n",
    "        - N: A list of time intervals (in minutes) for which future measurements are to be predicted\n",
    "        \n",
    "    OUTPUT:\n",
    "        - A tuple containing the future measurement values for each of the time intervals in N\n",
    "    \n",
    "    Example:\n",
    "    If N = [30, 60], then the function will return a tuple containing the predicted measurements 30 and 60 minutes \n",
    "    into the future from the current measurement in curr_measurement.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Take current measurement index (datetime)\n",
    "    curr_idx = curr_measurement.name\n",
    "    \n",
    "    # Go n units into the future for n in N\n",
    "    nearest_measurements = []\n",
    "    \n",
    "    for n in N:\n",
    "        # Calculate the datetime n minutes into the future\n",
    "        future_time = curr_idx + pd.Timedelta(minutes=n)\n",
    "        \n",
    "        # Calculate the time difference between each index in data and the future_time\n",
    "        time_diff = abs(data.index - future_time)\n",
    "        \n",
    "        # Find the index of the row with the smallest time difference (i.e., closest measurement)\n",
    "        nearest_idx = time_diff.argmin()\n",
    "        \n",
    "        # Get the row with the closest measurement and add the predicted measurement to the list\n",
    "        nearest_time = data.iloc[nearest_idx]\n",
    "        nearest_measurements.append(nearest_time[prediction_var])\n",
    "    \n",
    "    return tuple(nearest_measurements)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a902a59212cf4e96bb4a29655d481cbc",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "$$(5)$$ Integramos todo lo anterior en nuestra funci贸n build dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "3c99e46aec1843ba864fbbe4ee598aa1",
    "deepnote_app_coordinates": {
     "h": 31,
     "w": 12,
     "x": 0,
     "y": 261
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1683840319110,
    "source_hash": "57a7fcff"
   },
   "outputs": [],
   "source": [
    "def build_dataset(data: pd.DataFrame, N: list, prediction_var: str, scaler=None):\n",
    "    \"\"\"\n",
    "    Builds a dataset for time series prediction by creating X and Y matrices from the input data.\n",
    "\n",
    "    INPUT:\n",
    "        - data:           Pandas DataFrame containing the input data\n",
    "        - N:              List of integers representing the number of minutes into the future to predict for each sample\n",
    "        - prediction_var: String representing the name of the column to predict\n",
    "        - scaler:         Scaler object from sklearn.preprocessing to scale the input data\n",
    "\n",
    "    OUTPUT:\n",
    "        - Tuple of two numpy arrays: X matrix and Y matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the last hour of measurement\n",
    "    last_hour = data.tail(1).index[0] - pd.Timedelta(minutes=max(N))\n",
    "\n",
    "    # Drop the last hour of data\n",
    "    X = data.truncate(after=pd.Timestamp(last_hour))\n",
    "\n",
    "    # Build the Y matrix (the future measurements)\n",
    "    output_dims = (len(X), len(N))\n",
    "    Y = np.zeros(output_dims)\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        current = X.iloc[i].name\n",
    "        Y[i, :] = find_future_measurement(data = X.truncate(after=current),\n",
    "                                          N    = N,\n",
    "                                          curr_measurement = X.iloc[i],\n",
    "                                          prediction_var   = prediction_var)\n",
    "\n",
    "    # Scale the data if requested\n",
    "    if scaler is not None:\n",
    "        X = data_scaling(data=X, scaler=scaler, not_scaling_columns=[prediction_var])\n",
    "\n",
    "    # Use all the columns but the column we want to predict\n",
    "    cols = X.columns.difference([prediction_var])\n",
    "\n",
    "    return X[cols].to_numpy(), Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b66db4715c1f49e7842bf2b160aa9beb",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "$$(6)$$ Hacemos el train/test split para entrenar nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "1311f993d0564b5aafd9a76d818b50ad",
    "deepnote_app_coordinates": {
     "h": 9,
     "w": 12,
     "x": 0,
     "y": 293
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 39942,
    "execution_start": 1683840319151,
    "source_hash": "a854a205"
   },
   "outputs": [],
   "source": [
    "X, Y = build_dataset( data = features,\n",
    "                      N = [10, 15, 30, 60],\n",
    "                      prediction_var = 'hum_level')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
    "                                                    train_size   = 0.8,\n",
    "                                                    #shuffle = False,)\n",
    "                                                    random_state = 69,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9c51e3b3cdce4bcb866a94732429caf5",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Creaci贸n del modelo\n",
    "\n",
    "$$(1)$$ Modelo secuencial con funci贸n de activaci贸n ReLu y m茅trica de p茅rdida 'mse'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "179ffeb824ec424d916cf278ef92e7cf",
    "deepnote_app_coordinates": {
     "h": 8,
     "w": 12,
     "x": 0,
     "y": 303
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 20,
    "execution_start": 1683840359133,
    "source_hash": "3ffabe0e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 18:20:41.832705: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-13 18:20:41.834950: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    }
   ],
   "source": [
    "model =  keras.Sequential([ keras.layers.Dense(units=16, activation='relu'),\n",
    "                            keras.layers.Dense(units=32, activation='relu'),\n",
    "                            keras.layers.Dense(units=48, activation='relu'),\n",
    "                            keras.layers.Dense(units=4, activation='relu')])\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.01),\n",
    "              loss = 'mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "19fdab0f1e7541739e366261e41644e9",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "$$(2)$$ Configuraci贸n de hiperpar谩metros y entrenamiento del modelo, as铆 como guardado de su historial para entender su evoluci贸n en el tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "66ca2918d95f49e4b886aef7b9b6f347",
    "deepnote_app_coordinates": {
     "h": 30,
     "w": 12,
     "x": 0,
     "y": 312
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 46752,
    "execution_start": 1683840434596,
    "source_hash": "f1283ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 3s 2ms/step - loss: 590.8177 - val_loss: 591.3016\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 589.2266 - val_loss: 589.8150\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 592.0580 - val_loss: 591.0375\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 588.1240 - val_loss: 592.3433\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 592.9103 - val_loss: 589.9087\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 587.6174 - val_loss: 590.6229\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 588.9661 - val_loss: 590.4423\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 587.9001 - val_loss: 591.3406\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 588.4489 - val_loss: 589.8704\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 590.9172 - val_loss: 590.7881\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 590.5085 - val_loss: 590.1684\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 587.5443 - val_loss: 590.4315\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 589.0808 - val_loss: 589.7751\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 592.8438 - val_loss: 589.8054\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 589.9146 - val_loss: 591.0372\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 589.5291 - val_loss: 590.6905\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 587.0942 - val_loss: 590.2773\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 589.0364 - val_loss: 589.7619\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 590.7111 - val_loss: 590.2521\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 588.1368 - val_loss: 591.5848\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 591.3968 - val_loss: 589.9582\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 589.0824 - val_loss: 589.8944\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 588.4118 - val_loss: 590.1922\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 587.6038 - val_loss: 590.3840\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 589.5132 - val_loss: 589.9362\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 588.5275 - val_loss: 589.7683\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 590.2000 - val_loss: 590.6729\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 590.1591 - val_loss: 589.7549\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 589.9250 - val_loss: 590.9283\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 586.8530 - val_loss: 589.7631\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 590.4079 - val_loss: 589.7819\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 587.9715 - val_loss: 589.7631\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 589.7867 - val_loss: 590.2652\n",
      "Epoch 34/50\n",
      " 855/1000 [========================>.....] - ETA: 0s - loss: 589.1590"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs           = 50, \n",
    "                    batch_size       = 3,\n",
    "                    steps_per_epoch  = 1000,\n",
    "                    validation_split = 0.10,\n",
    "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=15)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "daceeeaa16a5446d846a330e0e365104",
    "deepnote_app_coordinates": {
     "h": 10,
     "w": 12,
     "x": 0,
     "y": 343
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1683840407243,
    "source_hash": "a07100b8"
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.plot(history.history['loss'], 'g', label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], 'b', label='Validation Loss')\n",
    "    #plt.xlim([0, 100])\n",
    "    #plt.ylim([0, 300])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b62b5e5f5b8046c083267a03096a4e53",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Observaci贸n de resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "5bdce3ecc82a47c2a5a2d50b41993c64",
    "deepnote_app_coordinates": {
     "h": 13,
     "w": 12,
     "x": 0,
     "y": 354
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 758,
    "execution_start": 1683840407248,
    "source_hash": "39089663"
   },
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "cf988d63e5e84f91bf96e404944f3baa",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 458,
    "execution_start": 1683840408078,
    "source_hash": "1febaa2d"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "57c8c7461b594b779fb0e3a38d912947",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 63,
    "execution_start": 1683840408587,
    "source_hash": "b9901948"
   },
   "outputs": [],
   "source": [
    "plt.scatter(list(range(len(y_test[:,0]))), abs(y_pred[:,0] - y_test[:,0]), s=1.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "8c414b30974c43ab9e64fc693cf5e1b9",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 478,
    "execution_start": 1683840408902,
    "source_hash": "bf59e26d"
   },
   "outputs": [],
   "source": [
    "plt.scatter(list(range(len(y_test[:,0]))), y_test[:,3], s=1.3)\n",
    "plt.scatter(list(range(len(y_pred[:,0]))), y_pred[:,3], s=1.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(model, X_test, y_test, N=[10, 15, 30, 60]):\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    mse_values = []\n",
    "    \n",
    "    for n in N:\n",
    "        mse = np.mean(np.abs(y_test[:,n] - y_pred[:,n]))\n",
    "        mse_values.append(mse)\n",
    "        plt.scatter(list(range(len(y_test[:,n]))), y_test[:,n], s=1.3, label=f\"True (N={n})\")\n",
    "        plt.scatter(list(range(len(y_pred[:,n]))), y_pred[:,n], s=1.3, label=f\"Predicted (N={n})\")\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.title(\"True vs. Predicted values\")\n",
    "    plt.show()\n",
    "    print(f\"MSE values: {mse_values}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "dc606d8a91cc4b9485b354e45df8a19c",
    "deepnote_app_coordinates": {
     "h": 12,
     "w": 12,
     "x": 0,
     "y": 368
    },
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## M茅tricas\n",
    "\n",
    "Se propone al menos una m茅trica de evaluaci贸n para cuantificar el desempe帽o del modelo. Las m茅tricas propuestas son apropiadas para el problema. Un resumen del flujo de trabajo para abordar el proyecto. Se comentan estrategias a utilizar, qu茅 an谩lisis de los datos se podr铆a requerir o qu茅 algoritmos se considerar谩n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2f341124d0a74c2a8be9b438d075188c",
    "deepnote_app_coordinates": {
     "h": 52,
     "w": 12,
     "x": 0,
     "y": 381
    },
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Estrategias y flujo de trabajo\n",
    "\n",
    "1. Preprocesamiento de datos, esto es: \n",
    "    - Extracci贸n de caracter铆sticas _(dada la naturaleza temporal de los datos, exploramos la extracci贸n de caracter铆sticas en intervalos de 10, 15, 30 y 60 minutos, para ayudar a nuestro modelo a hacer predicciones, sin recurrir a arquitecturas m谩s complejas)_.\n",
    "    -  Escalamiento de datos (vamos a probar si es mejor con o sin este escalamiento).\n",
    "    - Combinaci贸n de las distintas bases de datos de mediciones de variables ambientales _(en la prueba de concepto presentada anteriormente se hizo uso 煤nicamente de los datos de humedad para predecir los datos futuros de humedad, sin embargo queremos explorar si el incluir la influencia de otras variables ambientales nos ayuda a mejorar el resultado)_.\n",
    "\n",
    "2. Construcci贸n de distintas redes neuronales:\n",
    "    - Con arquitecturas diferentes.\n",
    "    - Funciones de activaci贸n diferentes.\n",
    "    - Hiperpar谩metros diferentes. \n",
    "\n",
    "Tooodo esto para encontrar la mejor red neuronal, de hecho vamos a hacer el top 3 de las mejores redes neuronales y trataremos de deducir algunas concluciones de sus arquitecturas e hiperpar谩metros en relaci贸n con los datos. \n",
    "\n",
    "3. Comparaci贸n con los resultados de la red neuronal que solo hace uso de las caracter铆sticas de la variable de predicci贸n, con la red que hace uso de otros datos ambientales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bb2044c6e3b54dbca2fb5ed3ae7225df",
    "deepnote_app_coordinates": {
     "h": 30,
     "w": 12,
     "x": 0,
     "y": 434
    },
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Vamos a hacer uso de las siguientes m茅tricas:\n",
    "\n",
    "- MSE (Mean Squared Error)\n",
    "- MAE (Mean Absolute Error) \n",
    "- RMSE (Root Mean Squared Error) \n",
    "\n",
    "Estas m茅tricas son apropiadas para evaluar el desempe帽o de un modelo en problemas de regresi贸n, ya que miden la diferencia entre los valores predichos y los valores reales de la variable objetivo.\n",
    "\n",
    "MSE mide el promedio del cuadrado de los errores, mientras que MAE mide el promedio de los errores en valor absoluto. RMSE es similar a MSE, pero toma la ra铆z cuadrada del promedio de los errores al cuadrado.\n",
    "\n",
    "Adem谩s, son adecuadas para nuestro problema porque estamos interesados en predecir valores continuos, como la temperatura, la presi贸n, la humedad y la luz. Y tambi茅n, son f谩ciles de entender y comunicar, y permiten comparar el desempe帽o de diferentes modelos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=ff9b19c4-718d-4116-a04b-62cd53a598e5' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_app_layout": "article",
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "21c5c2f1ab3e47cebaa2d02235fe75bb",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
